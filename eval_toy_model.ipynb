{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(filename)s: '\n",
    "                           '%(levelname)s: '\n",
    "                           '%(funcName)s(): '\n",
    "                           '%(lineno)d:\\t'\n",
    "                           '%(message)s')\n",
    "from absl import flags\n",
    "import tensorflow as tf\n",
    "\n",
    "log = logging.getLogger('tensorflow')\n",
    "log.setLevel('INFO')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'outputs'\n",
    "data_dir = ''\n",
    "dataset = 'TOY'\n",
    "noise_dim= 1\n",
    "\n",
    "# GENERIC PARAMS\n",
    "batch_size= 1024\n",
    "d_optimizer= 'ADAM'\n",
    "e_loss_lambda= 0.0\n",
    "e_optimizer= 'ADAM'\n",
    "encoder= 'ATTACHED'\n",
    "eval_loss= True\n",
    "g_optimizer= 'ADAM'\n",
    "soft_label = 0\n",
    "\n",
    "window_lambda = 0\n",
    "use_wgan = 0\n",
    "gcp_project= None\n",
    "iterations_per_loop= 200\n",
    "lambda_window= 1.0\n",
    "learning_rate= 0.0002\n",
    "noise_cov= 'IDENTITY'\n",
    "num_eval_images= 1024\n",
    "num_shards= None\n",
    "num_viz_images= 100\n",
    "reconstruction_loss= False\n",
    "soft_label_strength= 0.2\n",
    "tpu= ''\n",
    "tpu_zone= 'us-central1-f'\n",
    "train_steps_per_eval= 1000\n",
    "use_encoder= False\n",
    "use_tpu= False\n",
    "use_window_loss= False\n",
    "wgan_lambda= 10.0\n",
    "wgan_n= 5\n",
    "wgan_penalty= False\n",
    "\n",
    "ignore_params_check = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf_logging.py: INFO: info(): 115:\tCurrent parameters: {'batch_size': 1024,\n",
      " 'd_optimizer': 'ADAM',\n",
      " 'data_dir': '',\n",
      " 'dataset': 'TOY',\n",
      " 'e_loss_lambda': 0.0,\n",
      " 'e_optimizer': 'ADAM',\n",
      " 'encoder': 'ATTACHED',\n",
      " 'eval_loss': True,\n",
      " 'g_optimizer': 'ADAM',\n",
      " 'gcp_project': None,\n",
      " 'iterations_per_loop': 200,\n",
      " 'lambda_window': 0,\n",
      " 'learning_rate': 0.0002,\n",
      " 'model_dir': 'output/ToyModel_z1_AAA_lr0.0002',\n",
      " 'noise_cov': 'IDENTITY',\n",
      " 'noise_dim': 1,\n",
      " 'num_eval_images': 1024,\n",
      " 'num_shards': None,\n",
      " 'num_viz_images': 100,\n",
      " 'reconstruction_loss': False,\n",
      " 'soft_label_strength': 0,\n",
      " 'tpu': '',\n",
      " 'tpu_zone': 'us-central1-f',\n",
      " 'train_steps_per_eval': 1000,\n",
      " 'use_encoder': False,\n",
      " 'use_tpu': False,\n",
      " 'use_window_loss': False,\n",
      " 'wgan_lambda': 10.0,\n",
      " 'wgan_n': 5,\n",
      " 'wgan_penalty': 0}\n",
      "tf_logging.py: WARNING: warning(): 125:\tFolder exists but without parameters. The code is gonna run assuming the parameters were the same (but using the ones defined on this session).\n",
      "tf_logging.py: INFO: info(): 115:\tStart\n",
      "tf_logging.py: INFO: info(): 115:\tUsing config: {'_model_dir': 'output/ToyModel_z1_AAA_lr0.0002', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f85e5411e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=200, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
      "tf_logging.py: INFO: info(): 115:\t_TPUContext: eval_on_tpu True\n",
      "tf_logging.py: WARNING: warning(): 125:\teval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "from model import ToyModel as Model\n",
    "from datamanager.toydist_input_functions import generate_input_fn\n",
    "\n",
    "\n",
    "\n",
    "import shutil\n",
    "shutil.rmtree('outputs')\n",
    "\n",
    "##### START\n",
    "model = Model(model_dir=model_dir, data_dir=data_dir, dataset=dataset,\n",
    "            # Model parameters\n",
    "            learning_rate=learning_rate, batch_size=batch_size, noise_dim=noise_dim,\n",
    "            noise_cov=noise_cov, soft_label_strength=soft_label,\n",
    "            use_window_loss=use_window_loss, lambda_window=window_lambda,\n",
    "            # WGAN\n",
    "            use_wgan_penalty=use_wgan, wgan_lambda=wgan_lambda, wgan_n=wgan_n,\n",
    "            # Encoder\n",
    "            use_encoder=use_encoder, encoder=encoder, e_loss_lambda=e_loss_lambda,\n",
    "            # ¯\\_(ツ)_/¯\n",
    "            reconstruction_loss=reconstruction_loss,\n",
    "            # Optimizers\n",
    "            g_optimizer=g_optimizer, d_optimizer=d_optimizer, e_optimizer=e_optimizer,\n",
    "            # Training and prediction settings\n",
    "            iterations_per_loop=iterations_per_loop, num_viz_images=num_viz_images,\n",
    "            # Evaluation settings\n",
    "            eval_loss=eval_loss, train_steps_per_eval=train_steps_per_eval,\n",
    "            num_eval_images=num_eval_images,\n",
    "            # TPU settings\n",
    "            use_tpu=use_tpu, tpu=tpu, tpu_zone=tpu_zone,\n",
    "            gcp_project=gcp_project, num_shards=num_shards,\n",
    "            ignore_params_check=ignore_params_check)\n",
    "model.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf_logging.py: INFO: info(): 115:\tStarting training for 50000 steps, current step: 0\n",
      "tf_logging.py: INFO: info(): 115:\tStep: 0  -- (Next checkpoint 1000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 0 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 59.5495\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 60978.7\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.5305\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94751.2\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 95.5356\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 97828.4\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 94.9949\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 97274.8\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 95.3777\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 97666.8\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 95.9239\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 98226.1\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.6704\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94894.5\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 93.8665\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 96119.3\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 94.4357\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 96702.2\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 1000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tLoss for final step: 0.69314086.\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished training step 1000\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning eval on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tStarting evaluation at 2019-02-26-14:45:51\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-1000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tEvaluation [1/1]\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluation at 2019-02-26-14:45:51\n",
      "tf_logging.py: INFO: info(): 115:\tSaving dict for global step 1000: discriminator_accuracy = 0.4999523, discriminator_loss = 1.3864857, generator_loss = 0.6929601, global_step = 1000, loss = 0.6929601\n",
      "tf_logging.py: INFO: info(): 115:\tSaving 'checkpoint_path' summary for global step 1000: output/ToyModel_z1_AAA_lr0.0002/model.ckpt-1000\n",
      "tf_logging.py: INFO: info(): 115:\tevaluation_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluating\n",
      "tf_logging.py: INFO: info(): 115:\t{'discriminator_accuracy': 0.4999523, 'discriminator_loss': 1.3864857, 'generator_loss': 0.6929601, 'loss': 0.6929601, 'global_step': 1000}\n",
      "tf_logging.py: INFO: info(): 115:\tStep: 1000  -- (Next checkpoint 2000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-1000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 1000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 59.2471\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 60669.1\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 93.8106\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 96062\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 94.1255\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 96384.5\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 94.5088\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 96777\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 94.0199\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 96276.4\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 93.0134\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 95245.7\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 95.1256\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 97408.6\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 91.9456\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94152.3\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 93.5063\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 95750.4\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 2000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tLoss for final step: 0.6931464.\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished training step 2000\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning eval on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tStarting evaluation at 2019-02-26-14:46:07\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-2000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tEvaluation [1/1]\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluation at 2019-02-26-14:46:08\n",
      "tf_logging.py: INFO: info(): 115:\tSaving dict for global step 2000: discriminator_accuracy = 0.50028604, discriminator_loss = 1.3851513, generator_loss = 0.69429237, global_step = 2000, loss = 0.69429237\n",
      "tf_logging.py: INFO: info(): 115:\tSaving 'checkpoint_path' summary for global step 2000: output/ToyModel_z1_AAA_lr0.0002/model.ckpt-2000\n",
      "tf_logging.py: INFO: info(): 115:\tevaluation_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluating\n",
      "tf_logging.py: INFO: info(): 115:\t{'discriminator_accuracy': 0.50028604, 'discriminator_loss': 1.3851513, 'generator_loss': 0.69429237, 'loss': 0.69429237, 'global_step': 2000}\n",
      "tf_logging.py: INFO: info(): 115:\tStep: 2000  -- (Next checkpoint 3000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-2000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 2000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 54.9677\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 56286.9\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 89.7858\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 91940.6\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 88.2731\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 90391.7\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 88.193\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 90309.6\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 85.3555\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 87404.1\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 90.8739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 93054.9\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 90.7189\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 92896.1\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 91.1341\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 93321.3\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.7563\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94982.4\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 3000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tLoss for final step: 0.69314635.\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished training step 3000\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning eval on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tStarting evaluation at 2019-02-26-14:46:25\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-3000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tEvaluation [1/1]\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluation at 2019-02-26-14:46:26\n",
      "tf_logging.py: INFO: info(): 115:\tSaving dict for global step 3000: discriminator_accuracy = 0.49999958, discriminator_loss = 1.3862966, generator_loss = 0.69314635, global_step = 3000, loss = 0.69314635\n",
      "tf_logging.py: INFO: info(): 115:\tSaving 'checkpoint_path' summary for global step 3000: output/ToyModel_z1_AAA_lr0.0002/model.ckpt-3000\n",
      "tf_logging.py: INFO: info(): 115:\tevaluation_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluating\n",
      "tf_logging.py: INFO: info(): 115:\t{'discriminator_accuracy': 0.49999958, 'discriminator_loss': 1.3862966, 'generator_loss': 0.69314635, 'loss': 0.69314635, 'global_step': 3000}\n",
      "tf_logging.py: INFO: info(): 115:\tStep: 3000  -- (Next checkpoint 4000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-3000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 3000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 58.3101\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 59709.6\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 94.5044\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 96772.6\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 91.9551\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94162\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.7589\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94985.1\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 86.1789\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 88247.2\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 81.8465\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 83810.8\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 86.9383\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 89024.8\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 86.5615\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 88639\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 78.1857\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 80062.1\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 4000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tLoss for final step: 0.6931507.\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished training step 4000\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning eval on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tStarting evaluation at 2019-02-26-14:46:43\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-4000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tEvaluation [1/1]\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluation at 2019-02-26-14:46:44\n",
      "tf_logging.py: INFO: info(): 115:\tSaving dict for global step 4000: discriminator_accuracy = 0.4999801, discriminator_loss = 1.3863777, generator_loss = 0.6930689, global_step = 4000, loss = 0.6930689\n",
      "tf_logging.py: INFO: info(): 115:\tSaving 'checkpoint_path' summary for global step 4000: output/ToyModel_z1_AAA_lr0.0002/model.ckpt-4000\n",
      "tf_logging.py: INFO: info(): 115:\tevaluation_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluating\n",
      "tf_logging.py: INFO: info(): 115:\t{'discriminator_accuracy': 0.4999801, 'discriminator_loss': 1.3863777, 'generator_loss': 0.6930689, 'loss': 0.6930689, 'global_step': 4000}\n",
      "tf_logging.py: INFO: info(): 115:\tStep: 4000  -- (Next checkpoint 5000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-4000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 4000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 58.0947\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 59489\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.505\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94725.1\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.7705\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94997\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 94.0597\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 96317.1\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 93.3719\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 95612.9\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.4189\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94637\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 91.8369\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94041\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 93.2494\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 95487.4\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 95.9858\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 98289.5\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 5000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tLoss for final step: 0.69315076.\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished training step 5000\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning eval on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tStarting evaluation at 2019-02-26-14:47:01\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-5000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tEvaluation [1/1]\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluation at 2019-02-26-14:47:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf_logging.py: INFO: info(): 115:\tSaving dict for global step 5000: discriminator_accuracy = 0.49994606, discriminator_loss = 1.3865106, generator_loss = 0.6929169, global_step = 5000, loss = 0.6929169\n",
      "tf_logging.py: INFO: info(): 115:\tSaving 'checkpoint_path' summary for global step 5000: output/ToyModel_z1_AAA_lr0.0002/model.ckpt-5000\n",
      "tf_logging.py: INFO: info(): 115:\tevaluation_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluating\n",
      "tf_logging.py: INFO: info(): 115:\t{'discriminator_accuracy': 0.49994606, 'discriminator_loss': 1.3865106, 'generator_loss': 0.6929169, 'loss': 0.6929169, 'global_step': 5000}\n",
      "tf_logging.py: INFO: info(): 115:\tStep: 5000  -- (Next checkpoint 6000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-5000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 5000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 59.9152\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 61353.2\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.6462\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94869.7\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 93.4339\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 95676.3\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 95.219\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 97504.2\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 95.187\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 97471.5\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 93.7461\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 95996\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 90.3758\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 92544.8\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 93.699\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 95947.8\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.0235\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94232\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 6000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tLoss for final step: 0.69314516.\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished training step 6000\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning eval on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tStarting evaluation at 2019-02-26-14:47:18\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-6000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tEvaluation [1/1]\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluation at 2019-02-26-14:47:18\n",
      "tf_logging.py: INFO: info(): 115:\tSaving dict for global step 6000: discriminator_accuracy = 0.50000274, discriminator_loss = 1.3862807, generator_loss = 0.6931561, global_step = 6000, loss = 0.6931561\n",
      "tf_logging.py: INFO: info(): 115:\tSaving 'checkpoint_path' summary for global step 6000: output/ToyModel_z1_AAA_lr0.0002/model.ckpt-6000\n",
      "tf_logging.py: INFO: info(): 115:\tevaluation_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluating\n",
      "tf_logging.py: INFO: info(): 115:\t{'discriminator_accuracy': 0.50000274, 'discriminator_loss': 1.3862807, 'generator_loss': 0.6931561, 'loss': 0.6931561, 'global_step': 6000}\n",
      "tf_logging.py: INFO: info(): 115:\tStep: 6000  -- (Next checkpoint 7000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-6000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 6000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 59.6694\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 61101.5\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 94.6307\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 96901.8\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.8724\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 95101.3\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 91.8385\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94042.6\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.6447\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94868.2\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 95.6731\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 97969.3\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 91.8499\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94054.3\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.1361\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94347.4\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 94.8522\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 97128.7\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 7000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tLoss for final step: 0.69314504.\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished training step 7000\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning eval on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tStarting evaluation at 2019-02-26-14:47:35\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-7000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tEvaluation [1/1]\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluation at 2019-02-26-14:47:35\n",
      "tf_logging.py: INFO: info(): 115:\tSaving dict for global step 7000: discriminator_accuracy = 0.5000076, discriminator_loss = 1.386262, generator_loss = 0.6931908, global_step = 7000, loss = 0.6931908\n",
      "tf_logging.py: INFO: info(): 115:\tSaving 'checkpoint_path' summary for global step 7000: output/ToyModel_z1_AAA_lr0.0002/model.ckpt-7000\n",
      "tf_logging.py: INFO: info(): 115:\tevaluation_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluating\n",
      "tf_logging.py: INFO: info(): 115:\t{'discriminator_accuracy': 0.5000076, 'discriminator_loss': 1.386262, 'generator_loss': 0.6931908, 'loss': 0.6931908, 'global_step': 7000}\n",
      "tf_logging.py: INFO: info(): 115:\tStep: 7000  -- (Next checkpoint 8000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-7000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 7000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 58.8601\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 60272.7\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 96.0391\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 98344.1\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 93.3952\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 95636.7\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 94.7761\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 97050.7\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.0726\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94282.3\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 96.1232\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 98430.2\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.1451\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94356.6\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 91.3378\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 93529.9\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 96.7721\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 99094.6\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 8000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tLoss for final step: 0.6931631.\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished training step 8000\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning eval on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tStarting evaluation at 2019-02-26-14:47:52\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-8000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tEvaluation [1/1]\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluation at 2019-02-26-14:47:52\n",
      "tf_logging.py: INFO: info(): 115:\tSaving dict for global step 8000: discriminator_accuracy = 0.49999246, discriminator_loss = 1.3863224, generator_loss = 0.6931254, global_step = 8000, loss = 0.6931254\n",
      "tf_logging.py: INFO: info(): 115:\tSaving 'checkpoint_path' summary for global step 8000: output/ToyModel_z1_AAA_lr0.0002/model.ckpt-8000\n",
      "tf_logging.py: INFO: info(): 115:\tevaluation_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluating\n",
      "tf_logging.py: INFO: info(): 115:\t{'discriminator_accuracy': 0.49999246, 'discriminator_loss': 1.3863224, 'generator_loss': 0.6931254, 'loss': 0.6931254, 'global_step': 8000}\n",
      "tf_logging.py: INFO: info(): 115:\tStep: 8000  -- (Next checkpoint 9000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-8000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 8000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 59.1511\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 60570.7\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 95.0565\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 97337.9\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 93.8896\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 96143\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 86.1111\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 88177.7\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 88.0541\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 90167.4\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 87.4842\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 89583.8\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 89.7042\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 91857.1\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 84.3589\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 86383.5\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 94.2985\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 96561.6\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 9000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tLoss for final step: 0.6931432.\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished training step 9000\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning eval on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tStarting evaluation at 2019-02-26-14:48:09\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-9000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tEvaluation [1/1]\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluation at 2019-02-26-14:48:10\n",
      "tf_logging.py: INFO: info(): 115:\tSaving dict for global step 9000: discriminator_accuracy = 0.49999088, discriminator_loss = 1.3863275, generator_loss = 0.6931049, global_step = 9000, loss = 0.6931049\n",
      "tf_logging.py: INFO: info(): 115:\tSaving 'checkpoint_path' summary for global step 9000: output/ToyModel_z1_AAA_lr0.0002/model.ckpt-9000\n",
      "tf_logging.py: INFO: info(): 115:\tevaluation_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluating\n",
      "tf_logging.py: INFO: info(): 115:\t{'discriminator_accuracy': 0.49999088, 'discriminator_loss': 1.3863275, 'generator_loss': 0.6931049, 'loss': 0.6931049, 'global_step': 9000}\n",
      "tf_logging.py: INFO: info(): 115:\tStep: 9000  -- (Next checkpoint 10000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-9000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 9000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 54.0765\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 55374.4\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 63.7508\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 65280.8\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 70.0101\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 71690.3\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 82.8326\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 84820.6\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 67.9199\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 69549.9\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 67.4286\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 69046.9\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 61.2117\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 62680.8\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 59.2224\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 60643.7\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 62.222\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 63715.4\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 10000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tLoss for final step: 0.6931483.\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished training step 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning eval on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tStarting evaluation at 2019-02-26-14:48:31\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-10000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tEvaluation [1/1]\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluation at 2019-02-26-14:48:32\n",
      "tf_logging.py: INFO: info(): 115:\tSaving dict for global step 10000: discriminator_accuracy = 0.50011444, discriminator_loss = 1.385835, generator_loss = 0.6936084, global_step = 10000, loss = 0.6936084\n",
      "tf_logging.py: INFO: info(): 115:\tSaving 'checkpoint_path' summary for global step 10000: output/ToyModel_z1_AAA_lr0.0002/model.ckpt-10000\n",
      "tf_logging.py: INFO: info(): 115:\tevaluation_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluating\n",
      "tf_logging.py: INFO: info(): 115:\t{'discriminator_accuracy': 0.50011444, 'discriminator_loss': 1.385835, 'generator_loss': 0.6936084, 'loss': 0.6936084, 'global_step': 10000}\n",
      "tf_logging.py: INFO: info(): 115:\tStep: 10000  -- (Next checkpoint 11000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-10000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 10000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 53.0578\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 54331.2\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 77.7604\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 79626.6\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 79.7791\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 81693.8\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 85.604\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 87658.5\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 87.7984\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 89905.6\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.5449\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 94766\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 90.2358\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 92401.5\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 84.7945\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 86829.6\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 85.0123\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 87052.6\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 11000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tLoss for final step: 0.6931464.\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished training step 11000\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning eval on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tStarting evaluation at 2019-02-26-14:48:51\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-11000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tEvaluation [1/1]\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluation at 2019-02-26-14:48:51\n",
      "tf_logging.py: INFO: info(): 115:\tSaving dict for global step 11000: discriminator_accuracy = 0.5001012, discriminator_loss = 1.3858904, generator_loss = 0.6935323, global_step = 11000, loss = 0.6935323\n",
      "tf_logging.py: INFO: info(): 115:\tSaving 'checkpoint_path' summary for global step 11000: output/ToyModel_z1_AAA_lr0.0002/model.ckpt-11000\n",
      "tf_logging.py: INFO: info(): 115:\tevaluation_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluating\n",
      "tf_logging.py: INFO: info(): 115:\t{'discriminator_accuracy': 0.5001012, 'discriminator_loss': 1.3858904, 'generator_loss': 0.6935323, 'loss': 0.6935323, 'global_step': 11000}\n",
      "tf_logging.py: INFO: info(): 115:\tStep: 11000  -- (Next checkpoint 12000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-11000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 11000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 57.3813\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 58758.4\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 91.1054\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 93292\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 89.7214\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 91874.7\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 92.8736\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 95102.6\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 87.4087\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 89506.5\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 84.6558\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 86687.5\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 88.7417\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 90871.5\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 94.845\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 97121.3\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 91.3667\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 93559.5\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 12000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tLoss for final step: 0.69314635.\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished training step 12000\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning eval on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tStarting evaluation at 2019-02-26-14:49:08\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-12000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tEvaluation [1/1]\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluation at 2019-02-26-14:49:09\n",
      "tf_logging.py: INFO: info(): 115:\tSaving dict for global step 12000: discriminator_accuracy = 0.5000004, discriminator_loss = 1.3862914, generator_loss = 0.69314635, global_step = 12000, loss = 0.69314635\n",
      "tf_logging.py: INFO: info(): 115:\tSaving 'checkpoint_path' summary for global step 12000: output/ToyModel_z1_AAA_lr0.0002/model.ckpt-12000\n",
      "tf_logging.py: INFO: info(): 115:\tevaluation_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluating\n",
      "tf_logging.py: INFO: info(): 115:\t{'discriminator_accuracy': 0.5000004, 'discriminator_loss': 1.3862914, 'generator_loss': 0.69314635, 'loss': 0.69314635, 'global_step': 12000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf_logging.py: INFO: info(): 115:\tStep: 12000  -- (Next checkpoint 13000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-12000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 12000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 57.8428\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 59231\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 75.9688\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 77792\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 83.4452\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 85447.9\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 86.9183\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 89004.3\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 77.4431\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 79301.7\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 73.6644\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 75432.4\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 66.594\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 68192.3\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 81.5772\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 83535.1\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 90.8137\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 92993.3\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 13000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tLoss for final step: 0.6931533.\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished training step 13000\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning eval on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tStarting evaluation at 2019-02-26-14:49:27\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-13000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tEvaluation [1/1]\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluation at 2019-02-26-14:49:28\n",
      "tf_logging.py: INFO: info(): 115:\tSaving dict for global step 13000: discriminator_accuracy = 0.5000019, discriminator_loss = 1.3862873, generator_loss = 0.6931458, global_step = 13000, loss = 0.6931458\n",
      "tf_logging.py: INFO: info(): 115:\tSaving 'checkpoint_path' summary for global step 13000: output/ToyModel_z1_AAA_lr0.0002/model.ckpt-13000\n",
      "tf_logging.py: INFO: info(): 115:\tevaluation_loop marked as finished\n",
      "tf_logging.py: INFO: info(): 115:\tFinished evaluating\n",
      "tf_logging.py: INFO: info(): 115:\t{'discriminator_accuracy': 0.5000019, 'discriminator_loss': 1.3862873, 'generator_loss': 0.6931458, 'loss': 0.6931458, 'global_step': 13000}\n",
      "tf_logging.py: INFO: info(): 115:\tStep: 13000  -- (Next checkpoint 14000)\n",
      "tf_logging.py: INFO: info(): 115:\t['train.tfrecords']\n",
      "tf_logging.py: INFO: info(): 115:\tCalling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tRunning train on CPU\n",
      "tf_logging.py: INFO: info(): 115:\tDone calling model_fn.\n",
      "tf_logging.py: INFO: info(): 115:\tCreate CheckpointSaverHook.\n",
      "tf_logging.py: INFO: info(): 115:\tGraph was finalized.\n",
      "tf_logging.py: INFO: info(): 115:\tRestoring parameters from output/ToyModel_z1_AAA_lr0.0002/model.ckpt-13000\n",
      "tf_logging.py: INFO: info(): 115:\tRunning local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tDone running local_init_op.\n",
      "tf_logging.py: INFO: info(): 115:\tSaving checkpoints for 13000 into output/ToyModel_z1_AAA_lr0.0002/model.ckpt.\n",
      "tf_logging.py: INFO: info(): 115:\tglobal_step/sec: 58.4575\n",
      "tf_logging.py: INFO: info(): 115:\texamples/sec: 59860.4\n",
      "tf_logging.py: INFO: info(): 115:\ttraining_loop marked as finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-970929738d8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/NSC/Deep-Learning/project/unsupervised-medical-learning/src/core/core_model_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_steps, generate_input_fn)\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step: %s  -- (Next checkpoint %s)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             self.est.train(input_fn=generate_input_fn('TRAIN'),\n\u001b[0;32m--> 755\u001b[0;31m                         max_steps=next_checkpoint)\n\u001b[0m\u001b[1;32m    756\u001b[0m             \u001b[0mcurrent_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished training step %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcurrent_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m   2401\u001b[0m       return super(TPUEstimator, self).train(\n\u001b[1;32m   2402\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2403\u001b[0;31m           \u001b[0msaving_listeners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2404\u001b[0m       )\n\u001b[1;32m   2405\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1205\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1239\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1240\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1469\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    669\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1157\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/Anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(50000, generate_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.setLevel('CRITICAL')\n",
    "def get_sample(i):\n",
    "    input_fn = lambda params: {'random_noise' : tf.constant([[i]], dtype=tf.float32)}\n",
    "    return next(model.est.predict(input_fn))['generated_images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:53<00:00,  3.74it/s]\n"
     ]
    }
   ],
   "source": [
    "samples = [get_sample(i) for i in tqdm(np.linspace(-1, 1, 200))]\n",
    "samples = np.vstack(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f852d8901d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.scatter(samples[:,0], samples[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.2500953e-05, -1.1133615e-05], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sample(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
